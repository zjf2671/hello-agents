#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»£ç ç¤ºä¾‹ 09: å››ç§è®°å¿†ç±»å‹æ·±åº¦è§£æ
è¯¦ç»†å±•ç¤ºWorkingMemoryã€EpisodicMemoryã€SemanticMemoryã€PerceptualMemoryçš„å®ç°ç‰¹ç‚¹
"""

from dotenv import load_dotenv
load_dotenv()
import os
import time
import hashlib
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from hello_agents.tools import MemoryTool

class MemoryTypesDeepDive:
    """å››ç§è®°å¿†ç±»å‹æ·±åº¦è§£ææ¼”ç¤ºç±»"""
    
    def __init__(self):
        self.setup_memory_systems()
    
    def setup_memory_systems(self):
        """è®¾ç½®ä¸åŒçš„è®°å¿†ç³»ç»Ÿ"""
        print("ğŸ§  å››ç§è®°å¿†ç±»å‹æ·±åº¦è§£æ")
        print("=" * 60)
        
        # åˆ›å»ºä¸“é—¨çš„è®°å¿†å·¥å…·å®ä¾‹
        self.working_memory_tool = MemoryTool(
            user_id="working_memory_user",
            memory_types=["working"]
        )
        
        self.episodic_memory_tool = MemoryTool(
            user_id="episodic_memory_user", 
            memory_types=["episodic"]
        )
        
        self.semantic_memory_tool = MemoryTool(
            user_id="semantic_memory_user",
            memory_types=["semantic"]
        )
        
        self.perceptual_memory_tool = MemoryTool(
            user_id="perceptual_memory_user",
            memory_types=["perceptual"]
        )
        
        print("âœ… å››ç§è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def demonstrate_working_memory(self):
        """æ¼”ç¤ºå·¥ä½œè®°å¿†çš„ç‰¹ç‚¹"""
        print("\nğŸ’­ å·¥ä½œè®°å¿† (Working Memory) æ·±åº¦è§£æ")
        print("-" * 60)
        
        print("ğŸ” å·¥ä½œè®°å¿†ç‰¹ç‚¹:")
        print("â€¢ âš¡ è®¿é—®é€Ÿåº¦æå¿«ï¼ˆçº¯å†…å­˜å­˜å‚¨ï¼‰")
        print("â€¢ ğŸ“ å®¹é‡æœ‰é™ï¼ˆé»˜è®¤50æ¡è®°å¿†ï¼‰")
        print("â€¢ â° è‡ªåŠ¨è¿‡æœŸï¼ˆTTLæœºåˆ¶ï¼‰")
        print("â€¢ ğŸ”„ é€‚åˆä¸´æ—¶ä¿¡æ¯å­˜å‚¨")
        
        # æ¼”ç¤ºå®¹é‡é™åˆ¶
        print(f"\n1. å®¹é‡é™åˆ¶æ¼”ç¤º:")
        print("æ·»åŠ å¤§é‡ä¸´æ—¶è®°å¿†ï¼Œè§‚å¯Ÿå®¹é‡ç®¡ç†...")
        
        for i in range(8):
            content = f"ä¸´æ—¶å·¥ä½œè®°å¿† {i+1}: å½“å‰æ­£åœ¨å¤„ç†ä»»åŠ¡æ­¥éª¤ {i+1}"
            result = self.working_memory_tool.run({"action":"add",
                                                    "content":content,
                                                    "memory_type":"working",
                                                    "importance":0.3 + (i * 0.1),
                                                    "task_step":i+1})
            print(f"  æ·»åŠ è®°å¿† {i+1}: {result}")
        
        # æ£€æŸ¥å½“å‰çŠ¶æ€
        stats = self.working_memory_tool.run({"action":"stats"})
        print(f"\nå½“å‰å·¥ä½œè®°å¿†çŠ¶æ€: {stats}")
        
        # æ¼”ç¤ºTTLæœºåˆ¶
        print(f"\n2. TTLï¼ˆç”Ÿå­˜æ—¶é—´ï¼‰æœºåˆ¶æ¼”ç¤º:")
        
        # æ·»åŠ ä¸€äº›å¸¦æ—¶é—´æˆ³çš„è®°å¿†
        current_time = datetime.now()
        
        # æ¨¡æ‹Ÿä¸åŒæ—¶é—´çš„è®°å¿†
        time_memories = [
            ("åˆšåˆšçš„æƒ³æ³•", 0, 0.8),
            ("5åˆ†é’Ÿå‰çš„ä»»åŠ¡", 5, 0.6),
            ("10åˆ†é’Ÿå‰çš„æé†’", 10, 0.4),
            ("å¾ˆä¹…ä»¥å‰çš„ç¬”è®°", 30, 0.2)
        ]
        
        for content, minutes_ago, importance in time_memories:
            # è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿæ—¶é—´å·®å¼‚
            result = self.working_memory_tool.run({"action":"add",
                                                    "content":content,
                                                    "memory_type":"working",
                                                    "importance":importance,
                                                    "simulated_age_minutes":minutes_ago})
            print(f"  æ·»åŠ è®°å¿†: {content} (æ¨¡æ‹Ÿ {minutes_ago} åˆ†é’Ÿå‰)")
        
        # æ¼”ç¤ºå¿«é€Ÿæ£€ç´¢
        print(f"\n3. å¿«é€Ÿæ£€ç´¢æ¼”ç¤º:")
        
        search_queries = ["ä»»åŠ¡", "æƒ³æ³•", "æé†’"]
        
        for query in search_queries:
            start_time = time.time()
            results = self.working_memory_tool.run({"action":"search",
                                                     "query":query,
                                                     "memory_type":"working",
                                                     "limit":3})
            search_time = time.time() - start_time
            print(f"  æŸ¥è¯¢ '{query}': {search_time:.4f}ç§’")
            print(f"    ç»“æœ: {results[:100]}...")
        
        # æ¼”ç¤ºè‡ªåŠ¨æ¸…ç†
        print(f"\n4. è‡ªåŠ¨æ¸…ç†æœºåˆ¶:")
        
        # è·å–æ¸…ç†å‰çš„ç»Ÿè®¡
        before_stats = self.working_memory_tool.run({"action":"stats"})
        print(f"æ¸…ç†å‰: {before_stats}")
        
        # è§¦å‘æ¸…ç†ï¼ˆé€šè¿‡é—å¿˜ä½é‡è¦æ€§è®°å¿†ï¼‰
        forget_result = self.working_memory_tool.run({"action":"forget",
                                                       "strategy":"importance_based",
                                                       "threshold":0.4})
        print(f"æ¸…ç†ç»“æœ: {forget_result}")
        
        # è·å–æ¸…ç†åçš„ç»Ÿè®¡
        after_stats = self.working_memory_tool.run({"action":"stats"})
        print(f"æ¸…ç†å: {after_stats}")
    
    def demonstrate_episodic_memory(self):
        """æ¼”ç¤ºæƒ…æ™¯è®°å¿†çš„ç‰¹ç‚¹"""
        print("\nğŸ“– æƒ…æ™¯è®°å¿† (Episodic Memory) æ·±åº¦è§£æ")
        print("-" * 60)
        
        print("ğŸ” æƒ…æ™¯è®°å¿†ç‰¹ç‚¹:")
        print("â€¢ ğŸ“… å®Œæ•´çš„æ—¶é—´åºåˆ—è®°å½•")
        print("â€¢ ğŸ­ ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯")
        print("â€¢ ğŸ”— æ”¯æŒè®°å¿†é“¾æ¡æ„å»º")
        print("â€¢ ğŸ’¾ æŒä¹…åŒ–å­˜å‚¨")
        
        # æ¼”ç¤ºå®Œæ•´äº‹ä»¶è®°å½•
        print(f"\n1. å®Œæ•´äº‹ä»¶è®°å½•æ¼”ç¤º:")
        
        # æ¨¡æ‹Ÿä¸€ä¸ªå®Œæ•´çš„å­¦ä¹ ä¼šè¯
        learning_session = [
            {
                "content": "å¼€å§‹å­¦ä¹ Pythonæœºå™¨å­¦ä¹ ",
                "context": "å­¦ä¹ å¼€å§‹",
                "location": "å®¶é‡Œä¹¦æˆ¿",
                "mood": "ä¸“æ³¨",
                "importance": 0.7
            },
            {
                "content": "å­¦ä¹ äº†çº¿æ€§å›å½’çš„æ•°å­¦åŸç†",
                "context": "ç†è®ºå­¦ä¹ ",
                "chapter": "ç¬¬3ç« ",
                "difficulty": "ä¸­ç­‰",
                "importance": 0.8
            },
            {
                "content": "å®ç°äº†ç¬¬ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹",
                "context": "å®è·µç¼–ç¨‹",
                "code_lines": 45,
                "bugs_fixed": 2,
                "importance": 0.9
            },
            {
                "content": "å®Œæˆäº†è¯¾åç»ƒä¹ é¢˜",
                "context": "ç»ƒä¹ å·©å›º",
                "exercises_completed": 5,
                "accuracy": 0.8,
                "importance": 0.6
            },
            {
                "content": "æ€»ç»“ä»Šå¤©çš„å­¦ä¹ æ”¶è·",
                "context": "å­¦ä¹ æ€»ç»“",
                "key_concepts": ["çº¿æ€§å›å½’", "æ¢¯åº¦ä¸‹é™", "æŸå¤±å‡½æ•°"],
                "importance": 0.8
            }
        ]
        
        session_id = f"learning_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        for i, event in enumerate(learning_session):
            result = self.episodic_memory_tool.run({"action":"add",
                                                     "content":event["content"],
                                                     "memory_type":"episodic",
                                                     "importance":event["importance"],
                                                     "session_id":session_id,
                                                     "sequence_number":i+1,
                                                     **{k: v for k, v in event.items() if k not in ["content", "importance"]}})
            print(f"  äº‹ä»¶ {i+1}: {result}")
        
        # æ¼”ç¤ºæ—¶é—´åºåˆ—æ£€ç´¢
        print(f"\n2. æ—¶é—´åºåˆ—æ£€ç´¢æ¼”ç¤º:")
        
        # æŒ‰æ—¶é—´é¡ºåºæ£€ç´¢
        timeline_search = self.episodic_memory_tool.run({"action":"search",
                                                          "query":"å­¦ä¹ ",
                                                          "memory_type":"episodic",
                                                          "limit":10})
        print(f"å­¦ä¹ æ—¶é—´çº¿: {timeline_search}")
        
        # æŒ‰ä¼šè¯æ£€ç´¢
        session_search = self.episodic_memory_tool.run({"action":"search",
                                                         "query":"çº¿æ€§å›å½’",
                                                         "memory_type":"episodic",
                                                         "limit":5})
        print(f"ä¼šè¯å†…å®¹: {session_search}")
        
        # æ¼”ç¤ºä¸Šä¸‹æ–‡ä¸°å¯Œæ€§
        print(f"\n3. ä¸Šä¸‹æ–‡ä¿¡æ¯æ¼”ç¤º:")
        
        # æ·»åŠ å¸¦æœ‰ä¸°å¯Œä¸Šä¸‹æ–‡çš„è®°å¿†
        rich_context_memory = {
            "content": "å‚åŠ äº†AIæŠ€æœ¯åˆ†äº«ä¼š",
            "event_type": "conference",
            "location": "åŒ—äº¬å›½é™…ä¼šè®®ä¸­å¿ƒ",
            "speakers": ["å¼ æ•™æˆ", "æåšå£«", "ç‹å·¥ç¨‹å¸ˆ"],
            "topics": ["æ·±åº¦å­¦ä¹ ", "è‡ªç„¶è¯­è¨€å¤„ç†", "è®¡ç®—æœºè§†è§‰"],
            "attendees_count": 200,
            "duration_hours": 6,
            "weather": "æ™´æœ—",
            "transportation": "åœ°é“",
            "networking_contacts": 3,
            "key_insights": ["Transformeræ¶æ„çš„æ¼”è¿›", "å¤šæ¨¡æ€å­¦ä¹ çš„å‰æ™¯"],
            "follow_up_actions": ["é˜…è¯»æ¨èè®ºæ–‡", "å°è¯•æ–°æ¡†æ¶"],
            "satisfaction_rating": 9
        }
        
        context_result = self.episodic_memory_tool.run({"action":"add",
                                                         "content":rich_context_memory["content"],
                                                         "memory_type":"episodic",
                                                         "importance":0.9,
                                                         **{k: v for k, v in rich_context_memory.items() if k != "content"}})
        print(f"ä¸°å¯Œä¸Šä¸‹æ–‡è®°å¿†: {context_result}")
        
        # æ¼”ç¤ºè®°å¿†é“¾æ¡
        print(f"\n4. è®°å¿†é“¾æ¡æ„å»º:")
        
        # åˆ›å»ºç›¸å…³è”çš„è®°å¿†åºåˆ—
        memory_chain = [
            ("çœ‹åˆ°ä¸€ç¯‡å…³äºGPTçš„è®ºæ–‡", "trigger", None),
            ("å†³å®šæ·±å…¥ç ”ç©¶Transformeræ¶æ„", "decision", "trigger"),
            ("ä¸‹è½½å¹¶é˜…è¯»Attention is All You Needè®ºæ–‡", "action", "decision"),
            ("å®ç°äº†ç®€åŒ–ç‰ˆçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶", "implementation", "action"),
            ("åœ¨é¡¹ç›®ä¸­åº”ç”¨äº†å­¦åˆ°çš„çŸ¥è¯†", "application", "implementation")
        ]
        
        chain_memories = {}
        for content, chain_type, parent_type in memory_chain:
            parent_id = chain_memories.get(parent_type) if parent_type else None
            
            result = self.episodic_memory_tool.run({"action":"add",
                                                     "content":content,
                                                     "memory_type":"episodic",
                                                     "importance":0.7,
                                                     "chain_type":chain_type,
                                                     "parent_memory":parent_id,
                                                     "chain_id":"gpt_learning_chain"})
            
            # æå–è®°å¿†IDï¼ˆç®€åŒ–å¤„ç†ï¼‰
            memory_id = f"{chain_type}_memory"
            chain_memories[chain_type] = memory_id
            print(f"  é“¾æ¡è®°å¿†: {content} (ç±»å‹: {chain_type})")
        
        # æ£€ç´¢æ•´ä¸ªé“¾æ¡
        chain_search = self.episodic_memory_tool.run({"action":"search",
                                                        "query":"GPT Transformer",
                                                        "memory_type":"episodic",
                                                        "limit":8})
        print(f"è®°å¿†é“¾æ¡æ£€ç´¢: {chain_search}")
    
    def demonstrate_semantic_memory(self):
        """æ¼”ç¤ºè¯­ä¹‰è®°å¿†çš„ç‰¹ç‚¹"""
        print("\nğŸ§  è¯­ä¹‰è®°å¿† (Semantic Memory) æ·±åº¦è§£æ")
        print("-" * 60)
        
        print("ğŸ” è¯­ä¹‰è®°å¿†ç‰¹ç‚¹:")
        print("â€¢ ğŸ”— çŸ¥è¯†å›¾è°±ç»“æ„åŒ–å­˜å‚¨")
        print("â€¢ ğŸ¯ æ¦‚å¿µå’Œå…³ç³»çš„æŠ½è±¡è¡¨ç¤º")
        print("â€¢ ğŸ” è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢")
        print("â€¢ ğŸ§® æ”¯æŒæ¨ç†å’Œå…³è”")
        
        # æ¼”ç¤ºæ¦‚å¿µå­˜å‚¨
        print(f"\n1. æ¦‚å¿µçŸ¥è¯†å­˜å‚¨æ¼”ç¤º:")
        
        # æ·»åŠ ä¸åŒç±»å‹çš„æ¦‚å¿µçŸ¥è¯†
        concepts = [
            {
                "content": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œé€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼",
                "concept_type": "definition",
                "domain": "artificial_intelligence",
                "keywords": ["æœºå™¨å­¦ä¹ ", "äººå·¥æ™ºèƒ½", "ç®—æ³•", "æ•°æ®", "æ¨¡å¼"],
                "importance": 0.9
            },
            {
                "content": "ç›‘ç£å­¦ä¹ ä½¿ç”¨æ ‡è®°æ•°æ®è®­ç»ƒæ¨¡å‹ï¼ŒåŒ…æ‹¬åˆ†ç±»å’Œå›å½’ä¸¤å¤§ç±»ä»»åŠ¡",
                "concept_type": "category",
                "domain": "machine_learning",
                "parent_concept": "æœºå™¨å­¦ä¹ ",
                "subcategories": ["åˆ†ç±»", "å›å½’"],
                "importance": 0.8
            },
            {
                "content": "æ¢¯åº¦ä¸‹é™æ˜¯ä¸€ç§ä¼˜åŒ–ç®—æ³•ï¼Œé€šè¿‡è¿­ä»£æ›´æ–°å‚æ•°æ¥æœ€å°åŒ–æŸå¤±å‡½æ•°",
                "concept_type": "algorithm",
                "domain": "optimization",
                "mathematical_basis": "å¾®ç§¯åˆ†",
                "applications": ["ç¥ç»ç½‘ç»œè®­ç»ƒ", "çº¿æ€§å›å½’"],
                "importance": 0.8
            },
            {
                "content": "è¿‡æ‹Ÿåˆæ˜¯æŒ‡æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¡¨ç°å¾ˆå¥½ï¼Œä½†åœ¨æ–°æ•°æ®ä¸Šæ³›åŒ–èƒ½åŠ›å·®",
                "concept_type": "problem",
                "domain": "machine_learning",
                "causes": ["æ¨¡å‹å¤æ‚åº¦è¿‡é«˜", "è®­ç»ƒæ•°æ®ä¸è¶³"],
                "solutions": ["æ­£åˆ™åŒ–", "äº¤å‰éªŒè¯", "æ—©åœ"],
                "importance": 0.7
            }
        ]
        
        for concept in concepts:
            result = self.semantic_memory_tool.run({"action":"add",
                                                     "content":concept["content"],
                                                     "memory_type":"semantic",
                                                     "importance":concept["importance"],
                                                     **{k: v for k, v in concept.items() if k not in ["content", "importance"]}})
            print(f"  æ¦‚å¿µå­˜å‚¨: {concept['concept_type']} - {result}")
        
        # æ¼”ç¤ºå…³ç³»æ¨ç†
        print(f"\n2. å…³ç³»æ¨ç†æ¼”ç¤º:")
        
        # æ·»åŠ å…³ç³»çŸ¥è¯†
        relationships = [
            {
                "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é›†ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œ",
                "relation_type": "is_subset_of",
                "subject": "æ·±åº¦å­¦ä¹ ",
                "object": "æœºå™¨å­¦ä¹ ",
                "strength": 0.9
            },
            {
                "content": "å·ç§¯ç¥ç»ç½‘ç»œç‰¹åˆ«é€‚åˆå¤„ç†å›¾åƒæ•°æ®",
                "relation_type": "suitable_for",
                "subject": "å·ç§¯ç¥ç»ç½‘ç»œ",
                "object": "å›¾åƒå¤„ç†",
                "strength": 0.8
            },
            {
                "content": "åå‘ä¼ æ’­ç®—æ³•ç”¨äºè®­ç»ƒç¥ç»ç½‘ç»œ",
                "relation_type": "used_for",
                "subject": "åå‘ä¼ æ’­",
                "object": "ç¥ç»ç½‘ç»œè®­ç»ƒ",
                "strength": 0.9
            }
        ]
        
        for relation in relationships:
            result = self.semantic_memory_tool.run({"action":"add",
                                                     "content":relation["content"],
                                                     "memory_type":"semantic",
                                                     "importance":0.8,
                                                     **{k: v for k, v in relation.items() if k != "content"}})
            print(f"  å…³ç³»å­˜å‚¨: {relation['relation_type']} - {result}")
        
        # æ¼”ç¤ºè¯­ä¹‰æ£€ç´¢
        print(f"\n3. è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢:")
        
        semantic_queries = [
            "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "å¦‚ä½•é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆï¼Ÿ",
            "ç¥ç»ç½‘ç»œçš„è®­ç»ƒæ–¹æ³•",
            "å›¾åƒè¯†åˆ«æŠ€æœ¯"
        ]
        
        for query in semantic_queries:
            start_time = time.time()
            results = self.semantic_memory_tool.run({"action":"search",
                                                      "query":query,
                                                      "memory_type":"semantic",
                                                      "limit":3})
            search_time = time.time() - start_time
            print(f"  æŸ¥è¯¢: '{query}' ({search_time:.4f}ç§’)")
            print(f"    ç»“æœ: {results[:150]}...")
        
        # æ¼”ç¤ºçŸ¥è¯†å›¾è°±æ„å»º
        print(f"\n4. çŸ¥è¯†å›¾è°±æ„å»º:")
        
        # æ·»åŠ å®ä½“å’Œå…³ç³»
        entities_and_relations = [
            {
                "content": "TensorFlowæ˜¯Googleå¼€å‘çš„æ·±åº¦å­¦ä¹ æ¡†æ¶",
                "entity_type": "framework",
                "developer": "Google",
                "domain": "deep_learning",
                "language": "Python",
                "year": 2015
            },
            {
                "content": "PyTorchæ˜¯Facebookå¼€å‘çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œä»¥åŠ¨æ€å›¾è‘—ç§°",
                "entity_type": "framework", 
                "developer": "Facebook",
                "domain": "deep_learning",
                "feature": "dynamic_graph",
                "language": "Python"
            },
            {
                "content": "BERTæ˜¯åŸºäºTransformerçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹",
                "entity_type": "model",
                "architecture": "Transformer",
                "task": "natural_language_processing",
                "training_method": "pre_training"
            }
        ]
        
        for item in entities_and_relations:
            result = self.semantic_memory_tool.run({"action":"add",
                                                     "content":item["content"],
                                                     "memory_type":"semantic",
                                                     "importance":0.8,
                                                     **{k: v for k, v in item.items() if k != "content"}})
            print(f"  å®ä½“å…³ç³»: {item['entity_type']} - {result}")
        
        # è·å–è¯­ä¹‰è®°å¿†ç»Ÿè®¡
        semantic_stats = self.semantic_memory_tool.run({"action":"stats"})
        print(f"\nè¯­ä¹‰è®°å¿†ç»Ÿè®¡: {semantic_stats}")
    
    def demonstrate_perceptual_memory(self):
        """æ¼”ç¤ºæ„ŸçŸ¥è®°å¿†çš„ç‰¹ç‚¹"""
        print("\nğŸ‘ï¸ æ„ŸçŸ¥è®°å¿† (Perceptual Memory) æ·±åº¦è§£æ")
        print("-" * 60)
        
        print("ğŸ” æ„ŸçŸ¥è®°å¿†ç‰¹ç‚¹:")
        print("â€¢ ğŸ¨ å¤šæ¨¡æ€æ•°æ®æ”¯æŒ")
        print("â€¢ ğŸ”„ è·¨æ¨¡æ€ç›¸ä¼¼æ€§æœç´¢")
        print("â€¢ ğŸ“Š æ„ŸçŸ¥æ•°æ®çš„è¯­ä¹‰ç†è§£")
        print("â€¢ ğŸ¯ å†…å®¹ç”Ÿæˆå’Œæ£€ç´¢")
        
        # æ¼”ç¤ºæ–‡æœ¬æ„ŸçŸ¥è®°å¿†
        print(f"\n1. æ–‡æœ¬æ„ŸçŸ¥è®°å¿†:")
        
        text_perceptions = [
            {
                "content": "è¿™æ˜¯ä¸€æ®µä¼˜ç¾çš„è¯—æ­Œï¼šæ˜¥æ±Ÿæ½®æ°´è¿æµ·å¹³ï¼Œæµ·ä¸Šæ˜æœˆå…±æ½®ç”Ÿ",
                "modality": "text",
                "genre": "poetry",
                "emotion": "peaceful",
                "language": "chinese",
                "aesthetic_value": 0.9
            },
            {
                "content": "æŠ€æœ¯æ–‡æ¡£ï¼šAPIæ¥å£è¿”å›JSONæ ¼å¼æ•°æ®ï¼ŒåŒ…å«çŠ¶æ€ç å’Œå“åº”ä½“",
                "modality": "text",
                "genre": "technical",
                "complexity": "medium",
                "language": "chinese",
                "practical_value": 0.8
            }
        ]
        
        for perception in text_perceptions:
            result = self.perceptual_memory_tool.run({"action":"add",
                                                       "content":perception["content"],
                                                       "memory_type":"perceptual",
                                                       "importance":0.7,
                                                       **{k: v for k, v in perception.items() if k != "content"}})
            print(f"  æ–‡æœ¬æ„ŸçŸ¥: {perception['genre']} - {result}")
        
        # æ¼”ç¤ºå›¾åƒæ„ŸçŸ¥è®°å¿†ï¼ˆæ¨¡æ‹Ÿï¼‰
        print(f"\n2. å›¾åƒæ„ŸçŸ¥è®°å¿†ï¼ˆæ¨¡æ‹Ÿï¼‰:")
        
        # æ¨¡æ‹Ÿå›¾åƒæ•°æ®
        image_perceptions = [
            {
                "content": "ä¸€å¼ ç¾ä¸½çš„æ—¥è½é£æ™¯ç…§ç‰‡",
                "modality": "image",
                "file_path": "/simulated/sunset.jpg",
                "scene_type": "landscape",
                "colors": ["orange", "red", "purple"],
                "objects": ["sun", "clouds", "horizon"],
                "mood": "serene",
                "quality": "high"
            },
            {
                "content": "æŠ€æœ¯æ¶æ„å›¾å±•ç¤ºäº†å¾®æœåŠ¡ç³»ç»Ÿè®¾è®¡",
                "modality": "image", 
                "file_path": "/simulated/architecture.png",
                "diagram_type": "technical",
                "components": ["API Gateway", "Services", "Database"],
                "complexity": "high",
                "purpose": "documentation"
            }
        ]
        
        for perception in image_perceptions:
            result = self.perceptual_memory_tool.run({"action":"add",
                                                       "content":perception["content"],
                                                       "memory_type":"perceptual",
                                                       "importance":0.8,
                                                       **{k: v for k, v in perception.items() if k != "content"}})
            print(f"  å›¾åƒæ„ŸçŸ¥: {perception['content']} - {result}")
        
        # æ¼”ç¤ºéŸ³é¢‘æ„ŸçŸ¥è®°å¿†ï¼ˆæ¨¡æ‹Ÿï¼‰
        print(f"\n3. éŸ³é¢‘æ„ŸçŸ¥è®°å¿†ï¼ˆæ¨¡æ‹Ÿï¼‰:")
        
        audio_perceptions = [
            {
                "content": "ä¸€æ®µä¼˜ç¾çš„å¤å…¸éŸ³ä¹æ¼”å¥",
                "modality": "audio",
                "file_path": "/simulated/classical.mp3",
                "genre": "classical",
                "instruments": ["piano", "violin", "cello"],
                "tempo": "andante",
                "emotion": "elegant",
                "duration_seconds": 240
            },
            {
                "content": "æŠ€æœ¯ä¼šè®®çš„å½•éŸ³ï¼Œè®¨è®ºAIå‘å±•è¶‹åŠ¿",
                "modality": "audio",
                "file_path": "/simulated/conference.wav",
                "content_type": "speech",
                "topic": "artificial_intelligence",
                "speakers": 3,
                "language": "chinese",
                "duration_seconds": 1800
            }
        ]
        
        for perception in audio_perceptions:
            result = self.perceptual_memory_tool.run({"action":"add",
                                                       "content":perception["content"],
                                                       "memory_type":"perceptual",
                                                       "importance":0.7,
                                                       **{k: v for k, v in perception.items() if k != "content"}})
            print(f"  éŸ³é¢‘æ„ŸçŸ¥: {perception['content']} - {result}")
        
        # æ¼”ç¤ºè·¨æ¨¡æ€æ£€ç´¢
        print(f"\n4. è·¨æ¨¡æ€æ£€ç´¢æ¼”ç¤º:")
        
        cross_modal_queries = [
            ("ç¾ä¸½çš„é£æ™¯", "å¯»æ‰¾è§†è§‰ç¾æ„Ÿç›¸å…³å†…å®¹"),
            ("æŠ€æœ¯æ–‡æ¡£", "æŸ¥æ‰¾æŠ€æœ¯ç›¸å…³çš„å¤šæ¨¡æ€å†…å®¹"),
            ("éŸ³ä¹å’Œè‰ºæœ¯", "æ£€ç´¢è‰ºæœ¯ç›¸å…³çš„æ„ŸçŸ¥è®°å¿†"),
            ("ä¼šè®®å’Œè®¨è®º", "æŸ¥æ‰¾äº¤æµç›¸å…³çš„å†…å®¹")
        ]
        
        for query, description in cross_modal_queries:
            results = self.perceptual_memory_tool.run({"action":"search",
                                                        "query":query,
                                                        "memory_type":"perceptual",
                                                        "limit":3})
            print(f"  è·¨æ¨¡æ€æŸ¥è¯¢: '{query}' ({description})")
            print(f"    ç»“æœ: {results[:120]}...")
        
        # æ¼”ç¤ºæ„ŸçŸ¥ç‰¹å¾åˆ†æ
        print(f"\n5. æ„ŸçŸ¥ç‰¹å¾åˆ†æ:")
        
        # è·å–æ„ŸçŸ¥è®°å¿†ç»Ÿè®¡
        perceptual_stats = self.perceptual_memory_tool.run({"action":"stats"})
        print(f"æ„ŸçŸ¥è®°å¿†ç»Ÿè®¡: {perceptual_stats}")
        
        # åˆ†æä¸åŒæ¨¡æ€çš„åˆ†å¸ƒ
        modality_analysis = self.perceptual_memory_tool.run({"action":"search",
                                                              "query":"æ¨¡æ€åˆ†æ",
                                                              "memory_type":"perceptual",
                                                              "limit":10})
        print(f"æ¨¡æ€åˆ†å¸ƒåˆ†æ: {modality_analysis}")
    
    def demonstrate_memory_interactions(self):
        """æ¼”ç¤ºå››ç§è®°å¿†ç±»å‹çš„äº¤äº’"""
        print("\nğŸ”„ å››ç§è®°å¿†ç±»å‹äº¤äº’æ¼”ç¤º")
        print("-" * 60)
        
        print("ğŸ” è®°å¿†äº¤äº’æ¨¡å¼:")
        print("â€¢ ğŸ”„ å·¥ä½œè®°å¿† â†’ æƒ…æ™¯è®°å¿†ï¼ˆé‡è¦äº‹ä»¶å›ºåŒ–ï¼‰")
        print("â€¢ ğŸ“š æƒ…æ™¯è®°å¿† â†’ è¯­ä¹‰è®°å¿†ï¼ˆç»éªŒæŠ½è±¡åŒ–ï¼‰")
        print("â€¢ ğŸ‘ï¸ æ„ŸçŸ¥è®°å¿† â†’ å…¶ä»–è®°å¿†ï¼ˆå¤šæ¨¡æ€ä¿¡æ¯æ•´åˆï¼‰")
        print("â€¢ ğŸ§  è¯­ä¹‰è®°å¿† â†’ å·¥ä½œè®°å¿†ï¼ˆçŸ¥è¯†æ¿€æ´»ï¼‰")
        
        # æ¨¡æ‹Ÿä¸€ä¸ªå®Œæ•´çš„å­¦ä¹ è¿‡ç¨‹
        print(f"\nå®Œæ•´å­¦ä¹ è¿‡ç¨‹æ¨¡æ‹Ÿ:")
        
        # 1. æ„ŸçŸ¥é˜¶æ®µï¼šæ¥æ”¶å¤šæ¨¡æ€ä¿¡æ¯
        print(f"\n1. æ„ŸçŸ¥é˜¶æ®µ - æ¥æ”¶ä¿¡æ¯:")
        
        perceptual_input = self.perceptual_memory_tool.run({"action":"add",
                                                             "content":"è§‚çœ‹äº†ä¸€ä¸ªå…³äºæ·±åº¦å­¦ä¹ çš„è§†é¢‘æ•™ç¨‹",
                                                             "memory_type":"perceptual",
                                                             "importance":0.8,
                                                             "modality":"video",
                                                             "topic":"deep_learning",
                                                             "duration_minutes":45,
                                                             "quality":"high"})
        print(f"æ„ŸçŸ¥è®°å¿†: {perceptual_input}")
        
        # 2. å·¥ä½œè®°å¿†é˜¶æ®µï¼šä¸´æ—¶å¤„ç†å’Œæ€è€ƒ
        print(f"\n2. å·¥ä½œè®°å¿†é˜¶æ®µ - ä¸´æ—¶å¤„ç†:")
        
        working_thoughts = [
            "ç†è§£äº†å·ç§¯ç¥ç»ç½‘ç»œçš„åŸºæœ¬åŸç†",
            "éœ€è¦è®°ä½åå‘ä¼ æ’­çš„è®¡ç®—æ­¥éª¤",
            "æƒ³åˆ°äº†ä¹‹å‰å­¦è¿‡çš„çº¿æ€§ä»£æ•°çŸ¥è¯†",
            "è®¡åˆ’å®ç°ä¸€ä¸ªç®€å•çš„CNNæ¨¡å‹"
        ]
        
        for thought in working_thoughts:
            result = self.working_memory_tool.run({"action":"add",
                                                    "content":thought,
                                                    "memory_type":"working",
                                                    "importance":0.6,
                                                    "processing_stage":"active_thinking"})
            print(f"  å·¥ä½œè®°å¿†: {thought[:30]}... - {result}")
        
        # 3. æƒ…æ™¯è®°å¿†é˜¶æ®µï¼šè®°å½•å®Œæ•´å­¦ä¹ äº‹ä»¶
        print(f"\n3. æƒ…æ™¯è®°å¿†é˜¶æ®µ - äº‹ä»¶è®°å½•:")
        
        episodic_event = self.episodic_memory_tool.run({"action":"add",
                                                         "content":"å®Œæˆäº†æ·±åº¦å­¦ä¹ è§†é¢‘æ•™ç¨‹çš„å­¦ä¹ ï¼Œç†è§£äº†CNNçš„æ ¸å¿ƒæ¦‚å¿µ",
                                                         "memory_type":"episodic",
                                                         "importance":0.9,
                                                         "event_type":"learning_session",
                                                         "duration_minutes":45,
                                                         "location":"å®¶é‡Œ",
                                                         "learning_outcome":"ç†è§£CNNåŸç†",
                                                         "next_action":"å®è·µç¼–ç¨‹"})
        print(f"æƒ…æ™¯è®°å¿†: {episodic_event}")
        
        # 4. è¯­ä¹‰è®°å¿†é˜¶æ®µï¼šæŠ½è±¡çŸ¥è¯†å­˜å‚¨
        print(f"\n4. è¯­ä¹‰è®°å¿†é˜¶æ®µ - çŸ¥è¯†æŠ½è±¡:")
        
        semantic_knowledge = [
            {
                "content": "å·ç§¯ç¥ç»ç½‘ç»œé€šè¿‡å·ç§¯å±‚æå–å›¾åƒç‰¹å¾ï¼Œé€‚åˆè®¡ç®—æœºè§†è§‰ä»»åŠ¡",
                "concept": "CNN",
                "domain": "deep_learning",
                "application": "computer_vision"
            },
            {
                "content": "åå‘ä¼ æ’­ç®—æ³•é€šè¿‡é“¾å¼æ³•åˆ™è®¡ç®—æ¢¯åº¦ï¼Œç”¨äºæ›´æ–°ç½‘ç»œå‚æ•°",
                "concept": "backpropagation",
                "domain": "optimization",
                "mathematical_basis": "chain_rule"
            }
        ]
        
        for knowledge in semantic_knowledge:
            result = self.semantic_memory_tool.run({"action":"add",
                                                     "content":knowledge["content"],
                                                     "memory_type":"semantic",
                                                     "importance":0.8,
                                                     **{k: v for k, v in knowledge.items() if k != "content"}})
            print(f"  è¯­ä¹‰è®°å¿†: {knowledge['concept']} - {result}")
        
        # 5. è®°å¿†æ•´åˆæ¼”ç¤º
        print(f"\n5. è®°å¿†æ•´åˆæ¼”ç¤º:")
        
        # ä»å·¥ä½œè®°å¿†æ•´åˆåˆ°æƒ…æ™¯è®°å¿†
        consolidation_result = self.working_memory_tool.run({"action":"consolidate",
                                                              "from_type":"working",
                                                              "to_type":"episodic",
                                                              "importance_threshold":0.6})
        print(f"å·¥ä½œè®°å¿†æ•´åˆ: {consolidation_result}")
        
        # è·¨è®°å¿†ç±»å‹æ£€ç´¢
        print(f"\n6. è·¨è®°å¿†ç±»å‹æ£€ç´¢:")
        
        query = "æ·±åº¦å­¦ä¹ CNN"
        
        # åœ¨æ‰€æœ‰è®°å¿†ç±»å‹ä¸­æœç´¢
        memory_tools = [
            ("å·¥ä½œè®°å¿†", self.working_memory_tool),
            ("æƒ…æ™¯è®°å¿†", self.episodic_memory_tool),
            ("è¯­ä¹‰è®°å¿†", self.semantic_memory_tool),
            ("æ„ŸçŸ¥è®°å¿†", self.perceptual_memory_tool)
        ]
        
        for memory_name, tool in memory_tools:
            results = tool.run({"action":"search", "query":query, "limit":2})
            print(f"  {memory_name}æ£€ç´¢: {results[:80]}...")
        
        # è·å–æ‰€æœ‰è®°å¿†ç³»ç»Ÿçš„ç»Ÿè®¡
        print(f"\n7. ç³»ç»Ÿæ•´ä½“çŠ¶æ€:")
        
        for memory_name, tool in memory_tools:
            stats = tool.run({"action":"stats"})
            print(f"  {memory_name}: {stats}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  å››ç§è®°å¿†ç±»å‹æ·±åº¦è§£ææ¼”ç¤º")
    print("è¯¦ç»†å±•ç¤ºWorkingMemoryã€EpisodicMemoryã€SemanticMemoryã€PerceptualMemory")
    print("=" * 80)
    
    try:
        demo = MemoryTypesDeepDive()
        
        # 1. å·¥ä½œè®°å¿†æ¼”ç¤º
        demo.demonstrate_working_memory()
        
        # 2. æƒ…æ™¯è®°å¿†æ¼”ç¤º
        demo.demonstrate_episodic_memory()
        
        # 3. è¯­ä¹‰è®°å¿†æ¼”ç¤º
        demo.demonstrate_semantic_memory()
        
        # 4. æ„ŸçŸ¥è®°å¿†æ¼”ç¤º
        demo.demonstrate_perceptual_memory()
        
        # 5. è®°å¿†äº¤äº’æ¼”ç¤º
        demo.demonstrate_memory_interactions()
        
        print("\n" + "=" * 80)
        print("ğŸ‰ å››ç§è®°å¿†ç±»å‹æ·±åº¦è§£æå®Œæˆï¼")
        print("=" * 80)
        
        print("\nâœ¨ è®°å¿†ç±»å‹ç‰¹æ€§æ€»ç»“:")
        print("1. ğŸ’­ å·¥ä½œè®°å¿† - å¿«é€Ÿä¸´æ—¶å­˜å‚¨ï¼Œå®¹é‡æœ‰é™ï¼Œè‡ªåŠ¨è¿‡æœŸ")
        print("2. ğŸ“– æƒ…æ™¯è®°å¿† - å®Œæ•´äº‹ä»¶è®°å½•ï¼Œæ—¶é—´åºåˆ—ï¼Œä¸°å¯Œä¸Šä¸‹æ–‡")
        print("3. ğŸ§  è¯­ä¹‰è®°å¿† - æŠ½è±¡çŸ¥è¯†å­˜å‚¨ï¼Œæ¦‚å¿µå…³ç³»ï¼Œè¯­ä¹‰æ¨ç†")
        print("4. ğŸ‘ï¸ æ„ŸçŸ¥è®°å¿† - å¤šæ¨¡æ€æ”¯æŒï¼Œè·¨æ¨¡æ€æ£€ç´¢ï¼Œæ„ŸçŸ¥ç†è§£")
        
        print("\nğŸ”„ è®°å¿†äº¤äº’æ¨¡å¼:")
        print("â€¢ æ„ŸçŸ¥ â†’ å·¥ä½œ â†’ æƒ…æ™¯ â†’ è¯­ä¹‰ï¼ˆä¿¡æ¯å¤„ç†æµç¨‹ï¼‰")
        print("â€¢ è¯­ä¹‰ â†’ å·¥ä½œï¼ˆçŸ¥è¯†æ¿€æ´»å’Œåº”ç”¨ï¼‰")
        print("â€¢ è·¨ç±»å‹æ£€ç´¢å’Œæ•´åˆï¼ˆæ™ºèƒ½è®°å¿†ç®¡ç†ï¼‰")
        
        print("\nğŸ’¡ è®¾è®¡ä»·å€¼:")
        print("â€¢ æ¨¡æ‹Ÿäººç±»è®¤çŸ¥è¿‡ç¨‹")
        print("â€¢ æ”¯æŒå¤šå±‚æ¬¡ä¿¡æ¯å¤„ç†")
        print("â€¢ å®ç°æ™ºèƒ½è®°å¿†ç®¡ç†")
        print("â€¢ æä¾›ä¸°å¯Œçš„æ£€ç´¢èƒ½åŠ›")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()