#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»£ç ç¤ºä¾‹ 06: è®°å¿†æ•´åˆæœºåˆ¶æ¼”ç¤º
å±•ç¤ºä»çŸ­æœŸè®°å¿†åˆ°é•¿æœŸè®°å¿†çš„æ™ºèƒ½è½¬åŒ–è¿‡ç¨‹
"""

from dotenv import load_dotenv
load_dotenv()
import time
from datetime import datetime, timedelta
from hello_agents.tools import MemoryTool


class MemoryConsolidationDemo:
    """è®°å¿†æ•´åˆæ¼”ç¤ºç±»"""
    
    def __init__(self):
        self.memory_tool = MemoryTool(
            user_id="consolidation_demo_user",
            memory_types=["working", "episodic", "semantic", "perceptual"]
        )
    
    def setup_initial_memories(self):
        """è®¾ç½®åˆå§‹è®°å¿†æ•°æ®"""
        print("ğŸ“ è®¾ç½®åˆå§‹è®°å¿†æ•°æ®")
        print("=" * 50)
        
        # æ·»åŠ ä¸åŒé‡è¦æ€§çš„å·¥ä½œè®°å¿†
        working_memories = [
            {
                "content": "å­¦ä¹ äº†Transformeræ¶æ„çš„åŸºæœ¬åŸç†",
                "importance": 0.9,
                "topic": "deep_learning",
                "session": "study_session_1"
            },
            {
                "content": "å®Œæˆäº†Pythonä»£ç è°ƒè¯•ä»»åŠ¡",
                "importance": 0.8,
                "topic": "programming",
                "task_type": "debugging"
            },
            {
                "content": "å‚åŠ äº†å›¢é˜Ÿä¼šè®®è®¨è®ºé¡¹ç›®è¿›å±•",
                "importance": 0.7,
                "topic": "teamwork",
                "meeting_type": "progress_review"
            },
            {
                "content": "æŸ¥çœ‹äº†ä»Šå¤©çš„å¤©æ°”é¢„æŠ¥",
                "importance": 0.3,
                "topic": "daily_life",
                "category": "routine"
            },
            {
                "content": "é˜…è¯»äº†å…³äºæ³¨æ„åŠ›æœºåˆ¶çš„è®ºæ–‡",
                "importance": 0.85,
                "topic": "research",
                "paper_type": "technical"
            },
            {
                "content": "å–äº†ä¸€æ¯å’–å•¡",
                "importance": 0.2,
                "topic": "daily_life",
                "category": "routine"
            },
            {
                "content": "è§£å†³äº†ä¸€ä¸ªå¤æ‚çš„ç®—æ³•é—®é¢˜",
                "importance": 0.9,
                "topic": "problem_solving",
                "difficulty": "high"
            },
            {
                "content": "æ•´ç†äº†æ¡Œé¢æ–‡ä»¶",
                "importance": 0.4,
                "topic": "organization",
                "category": "maintenance"
            }
        ]
        
        print("æ·»åŠ å·¥ä½œè®°å¿†:")
        for i, memory in enumerate(working_memories):
            content = memory.pop("content")
            importance = memory.pop("importance")
            
            result = self.memory_tool.run({"action":"add",
                                            "content":content,
                                            "memory_type":"working",
                                            "importance":importance,
                                            **memory})
            
            print(f"  {i+1}. {content[:40]}... (é‡è¦æ€§: {importance})")
        
        print(f"\nâœ… å·²æ·»åŠ  {len(working_memories)} æ¡å·¥ä½œè®°å¿†")
        
        # æ˜¾ç¤ºå½“å‰çŠ¶æ€
        stats = self.memory_tool.run({"action":"stats"})
        print(f"\nğŸ“Š å½“å‰è®°å¿†ç»Ÿè®¡:\n{stats}")
    
    def demonstrate_consolidation_criteria(self):
        """æ¼”ç¤ºæ•´åˆæ ‡å‡†å’Œç­›é€‰è¿‡ç¨‹"""
        print("\nğŸ¯ è®°å¿†æ•´åˆæ ‡å‡†æ¼”ç¤º")
        print("-" * 50)
        
        print("æ•´åˆæ ‡å‡†:")
        print("â€¢ é‡è¦æ€§é˜ˆå€¼ç­›é€‰")
        print("â€¢ æŒ‰é‡è¦æ€§æ’åº")
        print("â€¢ ç±»å‹è½¬æ¢å¤„ç†")
        print("â€¢ å…ƒæ•°æ®æ›´æ–°")
        
        # è·å–å½“å‰å·¥ä½œè®°å¿†æ‘˜è¦
        print("\nğŸ“‹ æ•´åˆå‰çš„å·¥ä½œè®°å¿†çŠ¶æ€:")
        summary = self.memory_tool.run({"action":"summary", "limit":10})
        print(summary)
        
        # æµ‹è¯•ä¸åŒé˜ˆå€¼çš„æ•´åˆæ•ˆæœ
        thresholds = [0.5, 0.7, 0.8]
        
        for threshold in thresholds:
            print(f"\nğŸ” æµ‹è¯•é‡è¦æ€§é˜ˆå€¼ {threshold}:")
            
            # æ¨¡æ‹Ÿæ•´åˆè¿‡ç¨‹ï¼ˆä¸å®é™…æ‰§è¡Œï¼Œåªæ˜¯åˆ†æï¼‰
            working_memories = []
            # è¿™é‡Œåº”è¯¥ä»å®é™…çš„å·¥ä½œè®°å¿†ä¸­è·å–ï¼Œç®€åŒ–æ¼”ç¤º
            
            print(f"  é˜ˆå€¼ {threshold} ä¸‹ç¬¦åˆæ•´åˆæ¡ä»¶çš„è®°å¿†:")
            print(f"  â€¢ é‡è¦æ€§ >= {threshold} çš„è®°å¿†å°†è¢«æ•´åˆ")
            print(f"  â€¢ æ•´åˆåç±»å‹: working â†’ episodic")
            print(f"  â€¢ é‡è¦æ€§æå‡: importance Ã— 1.1")
    
    def demonstrate_consolidation_process(self):
        """æ¼”ç¤ºå®é™…çš„æ•´åˆè¿‡ç¨‹"""
        print("\nğŸ”„ è®°å¿†æ•´åˆè¿‡ç¨‹æ¼”ç¤º")
        print("-" * 50)
        
        print("æ•´åˆè¿‡ç¨‹æ­¥éª¤:")
        print("1. ç­›é€‰ç¬¦åˆæ¡ä»¶çš„è®°å¿†")
        print("2. æŒ‰é‡è¦æ€§æ’åº")
        print("3. åˆ›å»ºæ–°çš„è®°å¿†é¡¹")
        print("4. æ›´æ–°ç±»å‹å’Œå…ƒæ•°æ®")
        print("5. æ·»åŠ æ•´åˆæ ‡è®°")
        
        # æ‰§è¡Œä¸åŒé˜ˆå€¼çš„æ•´åˆ
        consolidation_tests = [
            (0.6, "ä½é˜ˆå€¼æ•´åˆ - æ•´åˆæ›´å¤šè®°å¿†"),
            (0.8, "é«˜é˜ˆå€¼æ•´åˆ - åªæ•´åˆæœ€é‡è¦çš„è®°å¿†")
        ]
        
        for threshold, description in consolidation_tests:
            print(f"\nğŸ”„ {description} (é˜ˆå€¼: {threshold}):")
            
            # è·å–æ•´åˆå‰çŠ¶æ€
            stats_before = self.memory_tool.run({"action":"stats"})
            print(f"æ•´åˆå‰çŠ¶æ€: {stats_before}")
            
            # æ‰§è¡Œæ•´åˆ
            start_time = time.time()
            consolidation_result = self.memory_tool.run({"action":"consolidate",
                                                          "from_type":"working",
                                                          "to_type":"episodic",
                                                          "importance_threshold":threshold})
            consolidation_time = time.time() - start_time
            
            print(f"æ•´åˆç»“æœ: {consolidation_result}")
            print(f"æ•´åˆè€—æ—¶: {consolidation_time:.3f}ç§’")
            
            # è·å–æ•´åˆåçŠ¶æ€
            stats_after = self.memory_tool.run({"action":"stats"})
            print(f"æ•´åˆåçŠ¶æ€: {stats_after}")
            
            # æŸ¥çœ‹æ•´åˆåçš„æƒ…æ™¯è®°å¿†
            print(f"\nğŸ“š æ•´åˆåçš„æƒ…æ™¯è®°å¿†:")
            episodic_search = self.memory_tool.run({"action":"search",
                                                     "query":"",
                                                     "memory_type":"episodic",
                                                     "limit":5})
            print(episodic_search)
    
    def demonstrate_consolidation_metadata(self):
        """æ¼”ç¤ºæ•´åˆè¿‡ç¨‹ä¸­çš„å…ƒæ•°æ®å¤„ç†"""
        print("\nğŸ“‹ æ•´åˆå…ƒæ•°æ®å¤„ç†æ¼”ç¤º")
        print("-" * 50)
        
        print("å…ƒæ•°æ®å¤„ç†:")
        print("â€¢ ä¿ç•™åŸå§‹å…ƒæ•°æ®")
        print("â€¢ æ·»åŠ æ•´åˆæ ‡è®°")
        print("â€¢ è®°å½•æ•´åˆæ—¶é—´")
        print("â€¢ ä¿å­˜åŸå§‹IDå¼•ç”¨")
        
        # æ·»åŠ ä¸€ä¸ªç‰¹æ®Šçš„å·¥ä½œè®°å¿†ç”¨äºæ¼”ç¤º
        special_memory_result = self.memory_tool.run({"action":"add",
            "content":"è¿™æ˜¯ä¸€ä¸ªç”¨äºæ¼”ç¤ºæ•´åˆå…ƒæ•°æ®å¤„ç†çš„ç‰¹æ®Šè®°å¿†",
            "memory_type":"working",
            "importance":0.85,
            "special_tag":"metadata_demo",
            "original_context":"demonstration",
            "creation_purpose":"show_consolidation_metadata"
        })
        
        print(f"æ·»åŠ ç‰¹æ®Šè®°å¿†: {special_memory_result}")
        
        # æ‰§è¡Œæ•´åˆ
        print(f"\nğŸ”„ æ‰§è¡Œæ•´åˆ...")
        consolidation_result = self.memory_tool.run({"action":"consolidate",
                                                       "from_type":"working",
                                                       "to_type":"episodic",
                                                       "importance_threshold":0.8})
        
        print(f"æ•´åˆç»“æœ: {consolidation_result}")
        
        # æœç´¢æ•´åˆåçš„è®°å¿†æŸ¥çœ‹å…ƒæ•°æ®
        print(f"\nğŸ” æŸ¥çœ‹æ•´åˆåçš„è®°å¿†å…ƒæ•°æ®:")
        search_result = self.memory_tool.run({"action":"search",
                                                "query":"ç‰¹æ®Šè®°å¿†",
                                                "memory_type":"episodic",
                                                "limit":1})
        print(search_result)
    
    def demonstrate_multi_type_consolidation(self):
        """æ¼”ç¤ºå¤šç±»å‹è®°å¿†æ•´åˆ"""
        print("\nğŸ”€ å¤šç±»å‹è®°å¿†æ•´åˆæ¼”ç¤º")
        print("-" * 50)
        
        print("å¤šç±»å‹æ•´åˆåœºæ™¯:")
        print("â€¢ working â†’ episodic (ç»å†è®°å½•)")
        print("â€¢ working â†’ semantic (çŸ¥è¯†æå–)")
        print("â€¢ episodic â†’ semantic (ç»éªŒæ€»ç»“)")
        
        # æ·»åŠ ä¸€äº›é€‚åˆä¸åŒæ•´åˆè·¯å¾„çš„è®°å¿†
        consolidation_candidates = [
            {
                "content": "å­¦ä¹ äº†æ·±åº¦å­¦ä¹ ä¸­çš„åå‘ä¼ æ’­ç®—æ³•åŸç†",
                "memory_type": "working",
                "importance": 0.9,
                "learning_type": "concept",
                "suitable_for": "semantic"
            },
            {
                "content": "ä»Šå¤©ä¸‹åˆå‚åŠ äº†AIæŠ€æœ¯åˆ†äº«ä¼š",
                "memory_type": "working", 
                "importance": 0.8,
                "event_type": "meeting",
                "suitable_for": "episodic"
            },
            {
                "content": "é€šè¿‡å¤šæ¬¡å®è·µæŒæ¡äº†Transformerçš„å®ç°æŠ€å·§",
                "memory_type": "episodic",
                "importance": 0.85,
                "experience_type": "skill",
                "suitable_for": "semantic"
            }
        ]
        
        print(f"\nğŸ“ æ·»åŠ æ•´åˆå€™é€‰è®°å¿†:")
        for memory in consolidation_candidates:
            content = memory.pop("content")
            memory_type = memory.pop("memory_type")
            importance = memory.pop("importance")
            suitable_for = memory.pop("suitable_for")
            
            result = self.memory_tool.run({"action":"add",
                                            "content":content,
                                            "memory_type":memory_type,
                                            "importance":importance,
                                            **memory})
            
            print(f"  â€¢ {content[:50]}... â†’ é€‚åˆæ•´åˆä¸º{suitable_for}")
        
        # æ‰§è¡Œä¸åŒç±»å‹çš„æ•´åˆ
        consolidation_paths = [
            ("working", "episodic", 0.75, "ç»å†è®°å½•æ•´åˆ"),
            ("working", "semantic", 0.85, "çŸ¥è¯†æå–æ•´åˆ"),
            ("episodic", "semantic", 0.8, "ç»éªŒæ€»ç»“æ•´åˆ")
        ]
        
        for from_type, to_type, threshold, description in consolidation_paths:
            print(f"\nğŸ”„ {description} ({from_type} â†’ {to_type}):")
            
            result = self.memory_tool.run({"action":"consolidate",
                                            "from_type":from_type,
                                            "to_type":to_type,
                                            "importance_threshold":threshold})
            
            print(f"æ•´åˆç»“æœ: {result}")
    
    def demonstrate_consolidation_benefits(self):
        """æ¼”ç¤ºè®°å¿†æ•´åˆçš„ç›Šå¤„"""
        print("\nâœ¨ è®°å¿†æ•´åˆç›Šå¤„æ¼”ç¤º")
        print("-" * 50)
        
        print("æ•´åˆç›Šå¤„:")
        print("â€¢ é•¿æœŸä¿å­˜é‡è¦ä¿¡æ¯")
        print("â€¢ é‡Šæ”¾å·¥ä½œè®°å¿†ç©ºé—´")
        print("â€¢ å½¢æˆçŸ¥è¯†ä½“ç³»")
        print("â€¢ æå‡æ£€ç´¢æ•ˆç‡")
        
        # è·å–æœ€ç»ˆçš„è®°å¿†ç³»ç»ŸçŠ¶æ€
        print(f"\nğŸ“Š æœ€ç»ˆè®°å¿†ç³»ç»ŸçŠ¶æ€:")
        final_stats = self.memory_tool.run({"action":"stats"})
        print(final_stats)
        
        # è·å–å„ç±»å‹è®°å¿†çš„æ‘˜è¦
        print(f"\nğŸ“‹ å„ç±»å‹è®°å¿†æ‘˜è¦:")
        
        memory_types = ["working", "episodic", "semantic"]
        for memory_type in memory_types:
            print(f"\n{memory_type.upper()}è®°å¿†:")
            type_summary = self.memory_tool.run({"action":"search",
                                                   "query":"",
                                                   "memory_type":memory_type,
                                                   "limit":3})
            print(type_summary)
        
        # æ¼”ç¤ºæ•´åˆåçš„æ£€ç´¢æ•ˆæœ
        print(f"\nğŸ” æ•´åˆåçš„æ£€ç´¢æ•ˆæœæµ‹è¯•:")
        search_queries = [
            ("æ·±åº¦å­¦ä¹ ", "æµ‹è¯•è·¨ç±»å‹æ£€ç´¢"),
            ("å­¦ä¹ ç»å†", "æµ‹è¯•æ•´åˆè®°å¿†æ£€ç´¢"),
            ("é‡è¦æ¦‚å¿µ", "æµ‹è¯•è¯­ä¹‰è®°å¿†æ£€ç´¢")
        ]
        
        for query, description in search_queries:
            print(f"\næŸ¥è¯¢: '{query}' ({description})")
            result = self.memory_tool.run({"action":"search",
                                            "query":query,
                                            "limit":3})
            print(result)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”„ è®°å¿†æ•´åˆæœºåˆ¶æ¼”ç¤º")
    print("å±•ç¤ºä»çŸ­æœŸè®°å¿†åˆ°é•¿æœŸè®°å¿†çš„æ™ºèƒ½è½¬åŒ–è¿‡ç¨‹")
    print("=" * 60)
    
    try:
        demo = MemoryConsolidationDemo()
        
        # 1. è®¾ç½®åˆå§‹è®°å¿†æ•°æ®
        demo.setup_initial_memories()
        
        # 2. æ¼”ç¤ºæ•´åˆæ ‡å‡†
        demo.demonstrate_consolidation_criteria()
        
        # 3. æ¼”ç¤ºæ•´åˆè¿‡ç¨‹
        demo.demonstrate_consolidation_process()
        
        # 4. æ¼”ç¤ºå…ƒæ•°æ®å¤„ç†
        demo.demonstrate_consolidation_metadata()
        
        # 5. æ¼”ç¤ºå¤šç±»å‹æ•´åˆ
        demo.demonstrate_multi_type_consolidation()
        
        # 6. æ¼”ç¤ºæ•´åˆç›Šå¤„
        demo.demonstrate_consolidation_benefits()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ è®°å¿†æ•´åˆæœºåˆ¶æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 60)
        
        print("\nâœ¨ è®°å¿†æ•´åˆæ ¸å¿ƒç‰¹æ€§:")
        print("1. ğŸ¯ æ™ºèƒ½ç­›é€‰ - åŸºäºé‡è¦æ€§é˜ˆå€¼çš„è‡ªåŠ¨ç­›é€‰")
        print("2. ğŸ”„ ç±»å‹è½¬æ¢ - çµæ´»çš„è®°å¿†ç±»å‹è½¬æ¢æœºåˆ¶")
        print("3. ğŸ“‹ å…ƒæ•°æ®ä¿æŒ - å®Œæ•´ä¿ç•™åŸå§‹ä¸Šä¸‹æ–‡ä¿¡æ¯")
        print("4. âš¡ è‡ªåŠ¨åŒ–å¤„ç† - æ— éœ€äººå·¥å¹²é¢„çš„è‡ªåŠ¨æ•´åˆ")
        print("5. ğŸ”€ å¤šè·¯å¾„æ”¯æŒ - æ”¯æŒå¤šç§æ•´åˆè·¯å¾„")
        
        print("\nğŸ¯ è®¾è®¡ç†å¿µ:")
        print("â€¢ ä»¿ç”Ÿæ€§ - æ¨¡æ‹Ÿäººç±»å¤§è„‘çš„è®°å¿†å›ºåŒ–è¿‡ç¨‹")
        print("â€¢ æ™ºèƒ½æ€§ - è‡ªåŠ¨è¯†åˆ«å’Œå¤„ç†é‡è¦ä¿¡æ¯")
        print("â€¢ çµæ´»æ€§ - æ”¯æŒå¤šç§æ•´åˆç­–ç•¥å’Œè·¯å¾„")
        print("â€¢ å®Œæ•´æ€§ - ä¿æŒè®°å¿†çš„å®Œæ•´æ€§å’Œå¯è¿½æº¯æ€§")
        
        print("\nğŸ’¡ åº”ç”¨ä»·å€¼:")
        print("â€¢ çŸ¥è¯†ç®¡ç† - å°†ä¸´æ—¶å­¦ä¹ è½¬åŒ–ä¸ºé•¿æœŸçŸ¥è¯†")
        print("â€¢ ç»éªŒç§¯ç´¯ - ä¿å­˜é‡è¦çš„å®è·µç»éªŒ")
        print("â€¢ ç³»ç»Ÿä¼˜åŒ– - é‡Šæ”¾çŸ­æœŸè®°å¿†ç©ºé—´")
        print("â€¢ æ™ºèƒ½å†³ç­– - åŸºäºå†å²ç»éªŒçš„å†³ç­–æ”¯æŒ")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()