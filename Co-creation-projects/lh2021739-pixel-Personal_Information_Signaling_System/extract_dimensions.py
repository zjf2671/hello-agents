"""
ç»´åº¦æå–æ¨¡å— - ä½¿ç”¨LLMä»æŠ¥å‘Šä¸­æå–ç»´åº¦
"""

import sys
import json
import os
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional

# è®¾ç½®æ§åˆ¶å°ç¼–ç ä¸ºUTF-8ï¼ˆWindowsï¼‰
# æ³¨æ„ï¼šåªåœ¨ä½œä¸ºä¸»è„šæœ¬è¿è¡Œæ—¶é‡å®šå‘ï¼Œé¿å…åœ¨è¢«å¯¼å…¥æ—¶å†²çª
if sys.platform == 'win32' and __name__ == "__main__":
    import io
    if not isinstance(sys.stdout, io.TextIOWrapper):
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    if not isinstance(sys.stderr, io.TextIOWrapper):
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# åŠ è½½ .env æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# å¯¼å…¥LLM
try:
    from hello_agents.core.llm import HelloAgentsLLM
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False
    print("âš ï¸  è­¦å‘Š: hello_agents æ¨¡å—æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨LLMæå–ç»´åº¦")


def init_llm():
    """åˆå§‹åŒ–LLM"""
    if not LLM_AVAILABLE:
        return None
    
    # ä»ç¯å¢ƒå˜é‡è¯»å–LLMé…ç½®
    llm_model = (
        os.getenv("LLM_MODEL") or
        os.getenv("LLM_MODEL_ID") or
        "qwen-plus"
    )
    llm_api_key = (
        os.getenv("LLM_API_KEY") or
        os.getenv("MODELSCOPE_API_KEY") or
        os.getenv("MODELSCOPE_API_TOKEN")
    )
    llm_base_url = (
        os.getenv("LLM_BASE_URL") or
        "https://api-inference.modelscope.cn/v1/"
    )
    llm_provider = os.getenv("LLM_PROVIDER", "modelscope")
    
    if not llm_api_key:
        print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°LLM API Key")
        return None
    
    try:
        llm = HelloAgentsLLM(
            model=llm_model,
            api_key=llm_api_key,
            base_url=llm_base_url,
            provider=llm_provider
        )
        return llm
    except Exception as e:
        print(f"âš ï¸  åˆå§‹åŒ–LLMå¤±è´¥: {e}")
        return None


def extract_json_from_text(text: str) -> Optional[Dict]:
    """ä»æ–‡æœ¬ä¸­æå–JSONå†…å®¹"""
    import re
    
    # å°è¯•ç›´æ¥è§£æ
    try:
        return json.loads(text.strip())
    except json.JSONDecodeError:
        pass
    
    # å°è¯•æå–JSONä»£ç å—
    json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group(1))
        except json.JSONDecodeError:
            pass
    
    # å°è¯•æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
    json_match = re.search(r'\{.*\}', text, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group(0))
        except json.JSONDecodeError:
            pass
    
    return None


def extract_dimensions_from_text(text: str, llm, existing_themes: List[str] = None) -> Dict:
    """ä»æŠ¥å‘Šæ–‡æœ¬ä¸­æå–ç»´åº¦
    
    Args:
        text: æŠ¥å‘Šæ–‡æœ¬å†…å®¹
        llm: LLMå®ä¾‹
        existing_themes: ç°æœ‰çš„themesåˆ—è¡¨ï¼Œç”¨äºå‚è€ƒæŠ½è±¡çº§åˆ«
    """
    if not llm:
        return {"dimensions": [], "confidence": 0.0, "error": "LLMæœªåˆå§‹åŒ–"}
    
    themes_hint = ""
    if existing_themes:
        themes_hint = f"\nå‚è€ƒç°æœ‰themesçš„é£æ ¼ï¼ˆè¿™äº›æ˜¯ç”¨æˆ·å·²ç»å®šä¹‰çš„å…´è¶£ä¸»é¢˜ï¼‰ï¼š{existing_themes}\næå–çš„ç»´åº¦åº”è¯¥ä¸è¿™äº›themesåœ¨æŠ½è±¡çº§åˆ«ä¸Šä¿æŒä¸€è‡´ã€‚"
    
    prompt = f"""è¯·ä»ä»¥ä¸‹ç”¨æˆ·æŠ¥å‘Šä¸­æå–3-8ä¸ªç»´åº¦ï¼ˆdimensionsï¼‰ã€‚ç»´åº¦åº”è¯¥æ˜¯ç”¨æˆ·å…³æ³¨çš„**é«˜çº§åˆ«çš„ä¸»é¢˜ã€é¢†åŸŸæˆ–å…´è¶£ç‚¹**ï¼Œè€Œä¸æ˜¯ç®€å•çš„åè¯æ‹†åˆ†ã€‚

æŠ¥å‘Šå†…å®¹ï¼š
{text}
{themes_hint}

**æå–åŸåˆ™**ï¼š
1. **ä¿æŒæ¦‚å¿µå®Œæ•´æ€§**ï¼šå¦‚æœæŠ¥å‘Šä¸­æåˆ°"ä¿¡æ¯ä¿¡å·ç³»ç»Ÿ"è¿™æ ·çš„å®Œæ•´æ¦‚å¿µï¼Œåº”è¯¥æå–ä¸º"ä¿¡æ¯ä¿¡å·ç³»ç»Ÿ"æˆ–"ç³»ç»Ÿ"ï¼Œè€Œä¸è¦æ‹†æˆ"ä¿¡æ¯"ã€"ä¿¡å·"ã€"ç³»ç»Ÿ"ä¸‰ä¸ªè¯
2. **æå–ä¸»é¢˜çº§åˆ«**ï¼šç»´åº¦åº”è¯¥æ˜¯ä¸»é¢˜çº§åˆ«çš„æ¦‚å¿µï¼ˆå¦‚"AI"ã€"å¥åº·"ã€"å·¥ä½œ"ï¼‰ï¼Œè€Œä¸æ˜¯å…·ä½“ç»†èŠ‚ï¼ˆå¦‚"æ›´æ–°"ã€"ä»Šå¤©"ã€"é«˜å…´"ï¼‰
3. **è¿‡æ»¤æ— å…³è¯**ï¼š
   - è¿‡æ»¤æ‰åŠ¨ä½œè¯ï¼ˆå¦‚ï¼šæ›´æ–°ã€åˆ›å»ºã€åˆ é™¤ï¼‰
   - è¿‡æ»¤æ‰æ—¶é—´è¯ï¼ˆå¦‚ï¼šä»Šå¤©ã€æ˜¨å¤©ã€æœ¬å‘¨ï¼‰
   - è¿‡æ»¤æ‰æƒ…ç»ªè¯ï¼ˆå¦‚ï¼šé«˜å…´ã€éš¾è¿‡ï¼‰ï¼Œé™¤éæƒ…ç»ªæœ¬èº«æ˜¯æŠ¥å‘Šçš„ä¸»é¢˜
   - è¿‡æ»¤æ‰è¿‡äºé€šç”¨çš„è¯ï¼ˆå¦‚ï¼šäº‹æƒ…ã€å†…å®¹ã€é—®é¢˜ï¼‰
4. **ç†è§£è¯­ä¹‰ä¸Šä¸‹æ–‡**ï¼šç†è§£æ•´ä¸ªå¥å­çš„å«ä¹‰ï¼Œæå–å…¶èƒŒåå…³æ³¨çš„ä¸»é¢˜
5. **æŠ½è±¡å±‚æ¬¡**ï¼šç»´åº¦åº”è¯¥æ˜¯è¶³å¤ŸæŠ½è±¡çš„ä¸»é¢˜ï¼Œå¯ä»¥ä½œä¸ºYouTubeæœç´¢å…³é”®è¯æˆ–å…´è¶£æ ‡ç­¾ä½¿ç”¨

**ç¤ºä¾‹**ï¼š
- æŠ¥å‘Šï¼š"ä»Šå¤©å¾ˆé«˜å…´ï¼Œæˆ‘ä»¬çš„ä¿¡æ¯ä¿¡å·ç³»ç»Ÿå†æ¬¡è¿æ¥äº†æ›´æ–°"
- âŒ é”™è¯¯æå–ï¼š["ä¿¡æ¯", "ä¿¡å·", "ç³»ç»Ÿ", "æ›´æ–°", "ä»Šå¤©"]
- âœ… æ­£ç¡®æå–ï¼š["ä¿¡æ¯ä¿¡å·ç³»ç»Ÿ"] æˆ– ["ç³»ç»Ÿ"] æˆ– ["æŠ€æœ¯ç³»ç»Ÿ"]

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»´åº¦åˆ—è¡¨ï¼š
{{
  "dimensions": ["ç»´åº¦1", "ç»´åº¦2", "ç»´åº¦3"],
  "confidence": 0.85,
  "reasoning": "ç®€è¦è¯´æ˜æå–ç†ç”±"
}}

è¦æ±‚ï¼š
- ç»´åº¦æ•°é‡ï¼š3-8ä¸ªï¼ˆæ ¹æ®æŠ¥å‘Šå†…å®¹çš„é‡è¦æ€§å†³å®šï¼‰
- ç»´åº¦æ ¼å¼ï¼šç®€æ´çš„ä¸»é¢˜è¯ï¼ˆ2-8ä¸ªå­—ï¼‰ï¼Œä¿æŒæ¦‚å¿µçš„å®Œæ•´æ€§
- confidenceï¼šæå–çš„ç½®ä¿¡åº¦ï¼ˆ0-1ä¹‹é—´ï¼‰
- reasoningï¼šç®€è¦è¯´æ˜ä¸ºä»€ä¹ˆæå–è¿™äº›ç»´åº¦

è¯·ç›´æ¥è¿”å›JSONï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚"""

    try:
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»æ–‡æœ¬ä¸­æå–é«˜çº§åˆ«çš„ä¸»é¢˜å’Œå…´è¶£ç»´åº¦ã€‚ä½ ä¼šç†è§£è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼Œä¿æŒæ¦‚å¿µçš„å®Œæ•´æ€§ï¼Œä¸ä¼šç®€å•åœ°è¿›è¡Œåˆ†è¯ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        response = llm.invoke(messages)
        
        # æå–JSON
        result = extract_json_from_text(response)
        
        if result and "dimensions" in result:
            return {
                "dimensions": result["dimensions"],
                "confidence": result.get("confidence", 0.8),
                "reasoning": result.get("reasoning", "")
            }
        else:
            print(f"âš ï¸  LLMè¿”å›æ ¼å¼ä¸æ­£ç¡®: {response[:200]}")
            return {"dimensions": [], "confidence": 0.0, "error": "æ ¼å¼è§£æå¤±è´¥"}
    
    except Exception as e:
        print(f"âš ï¸  æå–ç»´åº¦å¤±è´¥: {e}")
        return {"dimensions": [], "confidence": 0.0, "error": str(e)}


def extract_dimensions_from_report(report_file: Path, llm, existing_themes: List[str] = None) -> Optional[Dict]:
    """ä»Markdownæ–‡ä»¶ä¸­æå–ç»´åº¦
    
    Args:
        report_file: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        llm: LLMå®ä¾‹
        existing_themes: ç°æœ‰çš„themesåˆ—è¡¨ï¼Œç”¨äºå‚è€ƒæŠ½è±¡çº§åˆ«
    """
    if not report_file.exists():
        print(f"âŒ æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {report_file}")
        return None
    
    try:
        with open(report_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ç§»é™¤Markdownæ ‡é¢˜ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        lines = content.split('\n')
        # è·³è¿‡å¼€å¤´çš„#æ ‡é¢˜è¡Œ
        content_lines = []
        for line in lines:
            if line.strip().startswith('#') and not content_lines:
                continue
            content_lines.append(line)
        text = '\n'.join(content_lines).strip()
        
        if not text:
            print(f"âš ï¸  æŠ¥å‘Šå†…å®¹ä¸ºç©º: {report_file}")
            return None
        
        # æå–ç»´åº¦ï¼ˆä¼ å…¥existing_themesï¼‰
        result = extract_dimensions_from_text(text, llm, existing_themes=existing_themes)
        
        # æ·»åŠ æŠ¥å‘Šä¿¡æ¯
        result["report_file"] = str(report_file)
        result["report_date"] = report_file.stem
        result["extraction_date"] = datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ")
        
        return result
    
    except Exception as e:
        print(f"âŒ è¯»å–æŠ¥å‘Šå¤±è´¥ {report_file}: {e}")
        return None


def save_extraction_result(base_dir: Path, result: Dict, report_type: str):
    """ä¿å­˜æå–ç»“æœ"""
    dimensions_dir = base_dir / "archive" / "dimensions"
    dimensions_dir.mkdir(parents=True, exist_ok=True)
    
    # æ ¹æ®æŠ¥å‘Šæ—¥æœŸç”Ÿæˆæ–‡ä»¶å
    report_date = result.get("report_date", datetime.now().strftime("%Y-%m-%d"))
    output_file = dimensions_dir / f"{report_date}_{report_type}_dimensions.json"
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"âœ… ç»´åº¦æå–ç»“æœå·²ä¿å­˜: {output_file}")
        return output_file
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
        return None


def batch_extract_dimensions(base_dir: Path, report_type: str = None, llm=None, existing_themes: List[str] = None) -> List[Dict]:
    """æ‰¹é‡æå–ç»´åº¦
    
    Args:
        base_dir: åŸºç¡€ç›®å½•è·¯å¾„
        report_type: æŠ¥å‘Šç±»å‹ï¼ˆdaily/weekly/monthlyï¼‰ï¼ŒNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰ç±»å‹
        llm: LLMå®ä¾‹
        existing_themes: ç°æœ‰çš„themesåˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ä»themes.yamlåŠ è½½
    """
    if not llm:
        llm = init_llm()
        if not llm:
            print("âŒ LLMæœªåˆå§‹åŒ–ï¼Œæ— æ³•æå–ç»´åº¦")
            return []
    
    # å¦‚æœæ²¡æœ‰ä¼ å…¥existing_themesï¼Œå°è¯•ä»themes.yamlåŠ è½½
    if existing_themes is None:
        try:
            # é¿å…å¾ªç¯å¯¼å…¥ï¼Œç›´æ¥åœ¨è¿™é‡Œè¯»å–yaml
            import yaml
            themes_file = base_dir / "themes.yaml"
            if themes_file.exists():
                with open(themes_file, 'r', encoding='utf-8') as f:
                    data = yaml.safe_load(f)
                    if data and isinstance(data, dict):
                        existing_themes = data.get('themes', [])
                    else:
                        existing_themes = []
                if existing_themes:
                    print(f"ğŸ“Œ å·²åŠ è½½ {len(existing_themes)} ä¸ªç°æœ‰themesä½œä¸ºå‚è€ƒ: {existing_themes}")
        except Exception as e:
            print(f"âš ï¸  åŠ è½½themes.yamlå¤±è´¥ï¼Œå°†ä¸å‚è€ƒç°æœ‰themes: {e}")
            existing_themes = []
    
    reports_dir = base_dir / "archive" / "reports"
    results = []
    
    # ç¡®å®šè¦å¤„ç†çš„æŠ¥å‘Šç±»å‹
    types_to_process = [report_type] if report_type else ["daily", "weekly", "monthly"]
    
    for rtype in types_to_process:
        type_dir = reports_dir / rtype
        if not type_dir.exists():
            continue
        
        print(f"\nğŸ“‚ å¤„ç†{rtype}æŠ¥å‘Š...")
        report_files = sorted(type_dir.glob("*.md"))
        
        for report_file in report_files:
            print(f"  å¤„ç†: {report_file.name}")
            result = extract_dimensions_from_report(report_file, llm, existing_themes=existing_themes)
            
            if result and result.get("dimensions"):
                # æ·»åŠ æŠ¥å‘Šç±»å‹
                result["report_type"] = rtype
                
                # ä¿å­˜æå–ç»“æœ
                save_extraction_result(base_dir, result, rtype)
                
                results.append(result)
                print(f"    âœ… æå–åˆ° {len(result['dimensions'])} ä¸ªç»´åº¦: {', '.join(result['dimensions'][:5])}")
                # å¦‚æœæœ‰reasoningï¼Œä¹Ÿæ˜¾ç¤ºå‡ºæ¥ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                if result.get("reasoning"):
                    print(f"       æ¨ç†: {result['reasoning'][:100]}...")
            else:
                print(f"    âš ï¸  æœªæå–åˆ°ç»´åº¦")
    
    return results


def load_extraction_results(base_dir: Path) -> List[Dict]:
    """åŠ è½½æ‰€æœ‰æå–ç»“æœ"""
    dimensions_dir = base_dir / "archive" / "dimensions"
    
    if not dimensions_dir.exists():
        return []
    
    results = []
    for json_file in dimensions_dir.glob("*_dimensions.json"):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                result = json.load(f)
                results.append(result)
        except Exception as e:
            print(f"âš ï¸  è¯»å–æå–ç»“æœå¤±è´¥ {json_file.name}: {e}")
    
    return results


if __name__ == "__main__":
    # å‘½ä»¤è¡Œå·¥å…·
    import argparse
    
    parser = argparse.ArgumentParser(description="ä»æŠ¥å‘Šä¸­æå–ç»´åº¦")
    parser.add_argument("--report-type", choices=["daily", "weekly", "monthly"], 
                       help="æŒ‡å®šæŠ¥å‘Šç±»å‹ï¼ˆä¸æŒ‡å®šåˆ™å¤„ç†æ‰€æœ‰ç±»å‹ï¼‰")
    parser.add_argument("--report-file", type=str,
                       help="æŒ‡å®šå•ä¸ªæŠ¥å‘Šæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--base-dir", type=str,
                       help="åŸºç¡€ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ä¸ºè„šæœ¬æ‰€åœ¨ç›®å½•ï¼‰")
    
    args = parser.parse_args()
    
    base_dir = Path(args.base_dir) if args.base_dir else Path(__file__).parent
    
    llm = init_llm()
    if not llm:
        print("âŒ æ— æ³•åˆå§‹åŒ–LLMï¼Œé€€å‡º")
        sys.exit(1)
    
    # åŠ è½½existing_themesï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    existing_themes = None
    try:
        import yaml
        themes_file = base_dir / "themes.yaml"
        if themes_file.exists():
            with open(themes_file, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
                if data and isinstance(data, dict):
                    existing_themes = data.get('themes', [])
    except Exception:
        pass
    
    if args.report_file:
        # å¤„ç†å•ä¸ªæ–‡ä»¶
        report_file = Path(args.report_file)
        result = extract_dimensions_from_report(report_file, llm, existing_themes=existing_themes)
        if result:
            report_type = result.get("report_type", "daily")
            save_extraction_result(base_dir, result, report_type)
            print(f"\næå–çš„ç»´åº¦: {result.get('dimensions', [])}")
    else:
        # æ‰¹é‡å¤„ç†
        results = batch_extract_dimensions(base_dir, args.report_type, llm, existing_themes=existing_themes)
        print(f"\nâœ… å…±å¤„ç† {len(results)} ä¸ªæŠ¥å‘Š")

