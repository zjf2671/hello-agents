"""Reflection Agentå®ç° - è‡ªæˆ‘åæ€ä¸è¿­ä»£ä¼˜åŒ–çš„æ™ºèƒ½ä½“"""

from typing import Optional, List, Dict, Any
from core.agent import Agent
from core.llm import HelloAgentsLLM
from core.config import Config
from core.message import Message

# é»˜è®¤æç¤ºè¯æ¨¡æ¿
DEFAULT_PROMPTS = {
    "initial": """
è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚å®Œæˆä»»åŠ¡ï¼š

ä»»åŠ¡: {task}

è¯·æä¾›ä¸€ä¸ªå®Œæ•´ã€å‡†ç¡®çš„å›ç­”ã€‚
""",
    "reflect": """
è¯·ä»”ç»†å®¡æŸ¥ä»¥ä¸‹å›ç­”ï¼Œå¹¶æ‰¾å‡ºå¯èƒ½çš„é—®é¢˜æˆ–æ”¹è¿›ç©ºé—´ï¼š

# åŸå§‹ä»»åŠ¡:
{task}

# å½“å‰å›ç­”:
{content}

è¯·åˆ†æè¿™ä¸ªå›ç­”çš„è´¨é‡ï¼ŒæŒ‡å‡ºä¸è¶³ä¹‹å¤„ï¼Œå¹¶æå‡ºå…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚
å¦‚æœå›ç­”å·²ç»å¾ˆå¥½ï¼Œè¯·å›ç­”"æ— éœ€æ”¹è¿›"ã€‚
""",
    "refine": """
è¯·æ ¹æ®åé¦ˆæ„è§æ”¹è¿›ä½ çš„å›ç­”ï¼š

# åŸå§‹ä»»åŠ¡:
{task}

# ä¸Šä¸€è½®å›ç­”:
{last_attempt}

# åé¦ˆæ„è§:
{feedback}

è¯·æä¾›ä¸€ä¸ªæ”¹è¿›åçš„å›ç­”ã€‚
"""
}

class Memory:
    """
    ç®€å•çš„çŸ­æœŸè®°å¿†æ¨¡å—ï¼Œç”¨äºå­˜å‚¨æ™ºèƒ½ä½“çš„è¡ŒåŠ¨ä¸åæ€è½¨è¿¹ã€‚
    """
    def __init__(self):
        self.records: List[Dict[str, Any]] = []

    def add_record(self, record_type: str, content: str):
        """å‘è®°å¿†ä¸­æ·»åŠ ä¸€æ¡æ–°è®°å½•"""
        self.records.append({"type": record_type, "content": content})
        print(f"ğŸ“ è®°å¿†å·²æ›´æ–°ï¼Œæ–°å¢ä¸€æ¡ '{record_type}' è®°å½•ã€‚")

    def get_trajectory(self) -> str:
        """å°†æ‰€æœ‰è®°å¿†è®°å½•æ ¼å¼åŒ–ä¸ºä¸€ä¸ªè¿è´¯çš„å­—ç¬¦ä¸²æ–‡æœ¬"""
        trajectory = ""
        for record in self.records:
            if record['type'] == 'execution':
                trajectory += f"--- ä¸Šä¸€è½®å°è¯• (ä»£ç ) ---\n{record['content']}\n\n"
            elif record['type'] == 'reflection':
                trajectory += f"--- è¯„å®¡å‘˜åé¦ˆ ---\n{record['content']}\n\n"
        return trajectory.strip()

    def get_last_execution(self) -> str:
        """è·å–æœ€è¿‘ä¸€æ¬¡çš„æ‰§è¡Œç»“æœ"""
        for record in reversed(self.records):
            if record['type'] == 'execution':
                return record['content']
        return ""

class ReflectionAgent(Agent):
    """
    Reflection Agent - è‡ªæˆ‘åæ€ä¸è¿­ä»£ä¼˜åŒ–çš„æ™ºèƒ½ä½“

    è¿™ä¸ªAgentèƒ½å¤Ÿï¼š
    1. æ‰§è¡Œåˆå§‹ä»»åŠ¡
    2. å¯¹ç»“æœè¿›è¡Œè‡ªæˆ‘åæ€
    3. æ ¹æ®åæ€ç»“æœè¿›è¡Œä¼˜åŒ–
    4. è¿­ä»£æ”¹è¿›ç›´åˆ°æ»¡æ„

    ç‰¹åˆ«é€‚åˆä»£ç ç”Ÿæˆã€æ–‡æ¡£å†™ä½œã€åˆ†ææŠ¥å‘Šç­‰éœ€è¦è¿­ä»£ä¼˜åŒ–çš„ä»»åŠ¡ã€‚

    æ”¯æŒå¤šç§ä¸“ä¸šé¢†åŸŸçš„æç¤ºè¯æ¨¡æ¿ï¼Œç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰æˆ–ä½¿ç”¨å†…ç½®æ¨¡æ¿ã€‚
    """

    def __init__(
        self,
        name: str,
        llm: HelloAgentsLLM,
        system_prompt: Optional[str] = None,
        config: Optional[Config] = None,
        max_iterations: int = 3,
        custom_prompts: Optional[Dict[str, str]] = None
    ):
        """
        åˆå§‹åŒ–ReflectionAgent

        Args:
            name: Agentåç§°
            llm: LLMå®ä¾‹
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            config: é…ç½®å¯¹è±¡
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            custom_prompts: è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿ {"initial": "", "reflect": "", "refine": ""}
        """
        super().__init__(name, llm, system_prompt, config)
        self.max_iterations = max_iterations
        self.memory = Memory()

        # è®¾ç½®æç¤ºè¯æ¨¡æ¿ï¼šç”¨æˆ·è‡ªå®šä¹‰ä¼˜å…ˆï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤æ¨¡æ¿
        self.prompts = custom_prompts if custom_prompts else DEFAULT_PROMPTS
    
    def run(self, input_text: str, **kwargs) -> str:
        """
        è¿è¡ŒReflection Agent

        Args:
            input_text: ä»»åŠ¡æè¿°
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            æœ€ç»ˆä¼˜åŒ–åçš„ç»“æœ
        """
        print(f"\nğŸ¤– {self.name} å¼€å§‹å¤„ç†ä»»åŠ¡: {input_text}")

        # é‡ç½®è®°å¿†
        self.memory = Memory()

        # 1. åˆå§‹æ‰§è¡Œ
        print("\n--- æ­£åœ¨è¿›è¡Œåˆå§‹å°è¯• ---")
        initial_prompt = self.prompts["initial"].format(task=input_text)
        initial_result = self._get_llm_response(initial_prompt, **kwargs)
        self.memory.add_record("execution", initial_result)

        # 2. è¿­ä»£å¾ªç¯ï¼šåæ€ä¸ä¼˜åŒ–
        for i in range(self.max_iterations):
            print(f"\n--- ç¬¬ {i+1}/{self.max_iterations} è½®è¿­ä»£ ---")

            # a. åæ€
            print("\n-> æ­£åœ¨è¿›è¡Œåæ€...")
            last_result = self.memory.get_last_execution()
            reflect_prompt = self.prompts["reflect"].format(
                task=input_text,
                content=last_result
            )
            feedback = self._get_llm_response(reflect_prompt, **kwargs)
            self.memory.add_record("reflection", feedback)

            # b. æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
            if "æ— éœ€æ”¹è¿›" in feedback or "no need for improvement" in feedback.lower():
                print("\nâœ… åæ€è®¤ä¸ºç»“æœå·²æ— éœ€æ”¹è¿›ï¼Œä»»åŠ¡å®Œæˆã€‚")
                break

            # c. ä¼˜åŒ–
            print("\n-> æ­£åœ¨è¿›è¡Œä¼˜åŒ–...")
            refine_prompt = self.prompts["refine"].format(
                task=input_text,
                last_attempt=last_result,
                feedback=feedback
            )
            refined_result = self._get_llm_response(refine_prompt, **kwargs)
            self.memory.add_record("execution", refined_result)

        final_result = self.memory.get_last_execution()
        print(f"\n--- ä»»åŠ¡å®Œæˆ ---\næœ€ç»ˆç»“æœ:\n{final_result}")

        # ä¿å­˜åˆ°å†å²è®°å½•
        self.add_message(Message(input_text, "user"))
        self.add_message(Message(final_result, "assistant"))

        return final_result
    
    def _get_llm_response(self, prompt: str, **kwargs) -> str:
        """è°ƒç”¨LLMå¹¶è·å–å®Œæ•´å“åº”"""
        messages = [{"role": "user", "content": prompt}]
        return self.llm.invoke(messages, **kwargs) or ""
